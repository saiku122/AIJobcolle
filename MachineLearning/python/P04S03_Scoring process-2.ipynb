{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スコアリングフェーズにおけるデータ処理（解決編）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 課題把握編のおさらい\n",
    "前編にて、スコアリングデータのone-hotエンコーディング後に、以下の問題が生じる得ることを確認しました。<br>\n",
    "そこでこの問題が生じないよう、コードを補強していくことにしましょう。\n",
    "- モデルデータにないカラムが生成される可能性\n",
    "- モデルデータにあったカラムが消える可能性\n",
    "- データ型の違いが理由で上記を生じさせてしまう可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### データ前処理時の前提\n",
    "- 私達はどのデータが数値変数で、どのデータがカテゴリ変数かを事前に把握している\n",
    "- そして今回のカテゴリ変数は以下6変数とする\n",
    " - Dependents, Gender, Married, Education, Self_Employed, Property_Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理\n",
    "最初の補強は、ファイル読込段階で<b>カテゴリ変数をobject型として明記すること</b>です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ変数をリストで設定\n",
    "ohe_columns = ['Dependents',\n",
    "               'Gender',\n",
    "               'Married',\n",
    "               'Education',\n",
    "               'Self_Employed',\n",
    "               'Property_Area']\n",
    "\n",
    "# カテゴリ変数をobject型で読み込むための準備\n",
    "my_dtype = {'Dependents':object,\n",
    "            'Gender':object,\n",
    "            'Married':object,\n",
    "            'Education':object,\n",
    "            'Self_Employed':object,\n",
    "            'Property_Area':object}\n",
    "\n",
    "# 表示オプションの変更\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan screening model data for classification \n",
    "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv',\n",
    "                 header=0,\n",
    "                 dtype=my_dtype)\n",
    "\n",
    "X  = df.iloc[:,:-1]            # 最終列以前を特徴量\n",
    "ID = X.iloc[:,[0]]             # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "X  = X.drop('Loan_ID', axis=1) # Loan_IDは特徴ベクトルから削除\n",
    "y  = df.iloc[:,-1]             # 最終列を正解データ\n",
    "\n",
    "# check the shape\n",
    "print('---------------------------------')\n",
    "print('Raw shape: (%i,%i)' %df.shape)\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "print('---------------------------------')\n",
    "print(X.dtypes)\n",
    "\n",
    "# ローン審査でNOとなったサンプルを1（正例）として変換\n",
    "class_mapping = {'N':1, 'Y':0}\n",
    "y = y.map(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：カテゴリ変数の数量化と欠損対応\n",
    "ここに変更はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe = pd.get_dummies(X,\n",
    "                       dummy_na=True,\n",
    "                       columns=ohe_columns)\n",
    "\n",
    "print('X_ohe shape:(%i,%i)' % X_ohe.shape)\n",
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：数値変数の欠損値対応\n",
    "ここも変更はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer()\n",
    "imp.fit(X_ohe)\n",
    "\n",
    "X_ohe_columns = X_ohe.columns.values\n",
    "X_ohe = pd.DataFrame(imp.transform(X_ohe), columns=X_ohe_columns)\n",
    "\n",
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：次元圧縮（特徴量選択）\n",
    "最後に、RFEによる特徴量選択を実施します。<br>ここも変更ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "selector = RFE(RandomForestClassifier(n_estimators=100, random_state=1),\n",
    "               n_features_to_select=10,\n",
    "               step=.05)\n",
    "\n",
    "selector.fit(X_ohe,y)\n",
    "\n",
    "X_fin = X_ohe.loc[:, X_ohe_columns[selector.support_]]\n",
    "print('X_fin shape:(%i,%i)' % X_fin.shape)\n",
    "X_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上でモデリング段階の処理が終わりです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：データの読み込み\n",
    "さて、ここからがテスト用データへの処理です。<br>\n",
    "ここでも明示的に型を指定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan screening test data for classification \n",
    "df_s = pd.read_csv('./data/av_loan_test_Y3wMUE5_7gLdaTN.csv',\n",
    "                   header=0,\n",
    "                   dtype=my_dtype)\n",
    "\n",
    "ID_s = df_s.iloc[:,[0]]            # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "X_s  = df_s.drop('Loan_ID',axis=1) # Loan_IDは特徴ベクトルから削除\n",
    "\n",
    "# check the shape\n",
    "print('---------------------------------')\n",
    "print('Raw shape: (%i,%i)' %df_s.shape)\n",
    "print('X shape: (%i,%i)' %X_s.shape)\n",
    "print('---------------------------------')\n",
    "print(X_s.dtypes)\n",
    "ID_s.join(X_s).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：カテゴリ変数の数量化と欠損対応\n",
    "カテゴリ変数のデータ型をobject型に統一し、one-hotエンコーディングをしているので、`Dependents`変数関連の表記のブレが解消しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s = pd.get_dummies(X_s,\n",
    "                         dummy_na=True,\n",
    "                         columns=ohe_columns)\n",
    "print('X_ohe_s shape:(%i,%i)' % X_ohe_s.shape)\n",
    "X_ohe_s.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：one-hotエンコーディング後のデータ整合チェック\n",
    "さて、この時点の特徴量リストを再度比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_model = set(X_ohe.columns.values)\n",
    "cols_score = set(X_ohe_s.columns.values)\n",
    "\n",
    "diff1 = cols_model - cols_score\n",
    "print('モデルのみに存在する項目: %s' % diff1)\n",
    "\n",
    "diff2 = cols_score - cols_model\n",
    "print('スコアのみに存在する項目: %s' % diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 残されたデータ不整合\n",
    "データ型の違いによる不一致は消え、以下の違いだけが残りました。\n",
    "- Dependents_3+はスコアリングデータには存在しない\n",
    "- Gender_Unknownはスコアリングデータで新たに登場した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 不整合解消のための基本指針\n",
    "以下が基本方針となります。暗記ではなく、なぜそうすべきなのかを考えてみましょう。\n",
    "- モデル用にはあるが、スコア用に存在しない変数は復活させる\n",
    "- スコア用データにあるが、モデル用に存在しない変数は削除する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 不整合解消のためのtips：Pandasデータフレームのconcat関数\n",
    "上記指針実現の一つの方法が、データフレームを縦に結合するconcat処理です。<br>一旦サンプルデータからはなれ、concat関数の動作を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラム構成が同じデータフレームの結合\n",
    "df1 = pd.DataFrame([[1,2,3]], columns=['c1','c2','c3'])\n",
    "df2 = pd.DataFrame([[3,2,1]], columns=['c1','c2','c3'])\n",
    "df_all = pd.concat([df1, df2])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラム構成が異なるデータフレームの結合\n",
    "df3 = pd.DataFrame([[0,1,2,3]],columns=['c0','c1','c3','c4'])\n",
    "df_all = pd.concat([df_all, df3])\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### concat関数の動作\n",
    "- c0とc4は、元々のデータフレーム（df_all）に存在しなかった変数なので、スコア用データに初めて登場した変数と言えます。\n",
    " - よって、対応は削除となります。\n",
    "- 一方、c2はモデル用データにはあったがスコア用データにはなかった変数と言えます。\n",
    " - よって、対応は変数の復活です。\n",
    " - かつ、このような不一致はカテゴリ変数でのみ生じるので、ゼロ補完が妥当です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：one-hotエンコーディング後のデータ不整合の解消\n",
    "それではサンプルデータに戻ります。<br>\n",
    "モデリング時点のone-hotエンコーディング後のカラム構成は`X_ohe_columns`でした。<br>\n",
    "そこで、このカラム構成だけを持った（データ部分は持たない）データフレームを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols_m = pd.DataFrame(None,\n",
    "                         columns=X_ohe_columns,\n",
    "                         dtype=float)\n",
    "display(df_cols_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記に対し、スコアリング時点のone-hotエンコーディング後のデータを結合します。<br>\n",
    "実行し以下を確認しましょう。\n",
    "- `Dependents_3+`が復活（ただし、値は欠損状態）\n",
    "- `Gender_Unknown`はまだ存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s2 = pd.concat([df_cols_m, X_ohe_s])\n",
    "print(X_ohe_s2.shape)\n",
    "display(X_ohe_s2.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、スコアリングデータのみに登場する変数`Gender_Unknown`を削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_Xm = set(X_ohe.columns.values)\n",
    "set_Xs = set(X_ohe_s.columns.values)\n",
    "\n",
    "X_ohe_s3 = X_ohe_s2.drop(list(set_Xs-set_Xm),axis=1)\n",
    "\n",
    "print(X_ohe_s3.shape)\n",
    "display(X_ohe_s3.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、スコアリングでは登場しなかったデータ項目をゼロ埋めします。<br>\n",
    "実行し以下を確認しましょう。\n",
    "- 変数`Depend_3+`がゼロで埋まっていること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s3.loc[:,list(set_Xm-set_Xs)] = X_ohe_s3.loc[:,list(set_Xm-set_Xs)].fillna(0,axis=1)\n",
    "X_ohe_s3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：スコア用データの変数の並び順の制御\n",
    "最後に、モデリング時点のデータ項目の並び順を明示的に担保しましょう。<br>\n",
    "以下の通り、`reindex`関数を使うことで並び順を制御できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame([[1,2,3]], columns=['c1','c2','c3'])\n",
    "display(test)\n",
    "test = test.reindex(['c2','c3','c1'], axis=1)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、モデリング時点のone-hotエンコーディング後の並び順に制御します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s3 = X_ohe_s3.reindex(X_ohe.columns.values,axis=1)\n",
    "X_ohe_s3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：数値変数の欠損値対応\n",
    "ここまで整合させてようやく、学習済みSimpleImputerインスタンスが適用可能となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('欠損個数（数値変数の欠損補完前）',X_ohe_s3.isnull().sum().sum())\n",
    "X_ohe_s4 = pd.DataFrame(imp.transform(X_ohe_s3),columns=X_ohe_columns)\n",
    "print('欠損個数（数値変数の欠損補完後）',X_ohe_s4.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFEによって選択された変数の位置はsupport_属性から取得できたので、<br>スコアリングデータの特徴量の最終形は以下のようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：特徴量選択\n",
    "学習済みのRFEクラスのインスタンス（本ファイルではselector）を使って、選択された特徴量のインデックスを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fin_s = X_ohe_s4.loc[:, X_ohe_columns[selector.support_]]\n",
    "print(X_fin_s.shape)\n",
    "X_fin_s.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、スコアリング段階におけるデータの前処理が終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[やってみよう]</b> 本ファイルのタイトルをおさらいし、黒ペンで、モデル用データの前処理、スコア用データの前処理の手順をノートに一度書き出そう。色ペンに持ち替え、各処理の内容を書き加えていこう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
