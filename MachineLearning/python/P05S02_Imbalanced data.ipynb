{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "P05S02_Imbalanced data.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JspC8uesJ8V"
      },
      "source": [
        "## 不均衡データへの対応"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1GTs8WEsN5H",
        "outputId": "8079bd51-c211-4870-a7b3-f6ead451967d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/saiku122/AIJobcolle.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIJobcolle'...\n",
            "remote: Enumerating objects: 279, done.\u001b[K\n",
            "remote: Counting objects: 100% (279/279), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 279 (delta 108), reused 155 (delta 46), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (279/279), 11.70 MiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWbCUIBssTB0",
        "outputId": "9b1b66bc-7ac8-4e4b-a204-1aab4001dc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/AIJobcolle/MachineLearning/python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AIJobcolle/MachineLearning/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeWNwklqsJ8k"
      },
      "source": [
        "まず分類用のサンプルデータであるローン審査データを読み込みます。<br>データ前処理はone-hotエンコーディングと欠損値補完までを行っています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "42JcSlUNsJ8m"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# import data\n",
        "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv', header=0)\n",
        "X = df.iloc[:, :-1]          # 最終列外を特徴量X\n",
        "X = X.drop('Loan_ID',axis=1) # Loan_IDはID情報のため特徴量から削除\n",
        "y = df.iloc[:,-1]            # 最終列を正解データ\n",
        "\n",
        "# ローン審査でNOとなったサンプルを1に変換\n",
        "class_mapping = {'N':1, 'Y':0}\n",
        "y = y.map(class_mapping)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBX8A8rsJ8o",
        "outputId": "461dea7e-a879-446f-b509-84387d12e0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# one-hot エンコーディング\n",
        "ohe_columns = ['Dependents',\n",
        "               'Gender',\n",
        "               'Married',\n",
        "               'Education',\n",
        "               'Self_Employed',\n",
        "               'Property_Area']\n",
        "\n",
        "X_ohe = pd.get_dummies(X,\n",
        "                       dummy_na=True,\n",
        "                       columns=ohe_columns)\n",
        "\n",
        "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
        "imp.fit(X_ohe)\n",
        "X_ohe_columns = X_ohe.columns.values\n",
        "X_ohe = pd.DataFrame(imp.transform(X_ohe), columns=X_ohe_columns)\n",
        "\n",
        "display(X_ohe.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0bc3eada0fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                        columns=ohe_columns)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_ohe_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_ohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Imputer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y8xGBqysJ8p"
      },
      "source": [
        "### アンダーサンプリング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9roPIt_VsJ8q"
      },
      "source": [
        "アンダーサンプリングの実装例です。<br>負例（422件）が正例の件数（192件）まで削減されていることが確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcLJXPEXsJ8r"
      },
      "source": [
        "# ランダムアンダーサンプリング\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_under, y_under = rus.fit_sample(X_ohe, y)\n",
        "Counter(y_under)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CFBrGrqsJ8s"
      },
      "source": [
        "### オーバーサンプリング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG47oJXjsJ8s"
      },
      "source": [
        "以下、オーバーサンプリングの実装例です。<br>正例（192件）が負例の件数（422件）まで増加していることが確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MgBcafosJ8t"
      },
      "source": [
        "# ランダムオーバーサンプリング, SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "smt = SMOTE(random_state=0)\n",
        "\n",
        "X_over,y_over = ros.fit_sample(X_ohe, y)\n",
        "X_smt,y_smt = smt.fit_sample(X_ohe, y)\n",
        "\n",
        "print('Random Over Sampler',Counter(y_over))\n",
        "print('SMOTE', Counter(y_smt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHqy5XC4sJ8u"
      },
      "source": [
        "最後に、不均衡対応別のモデルの比較評価の実行例を確認します。<b><br>モデルの評価用データはリサンプリング前に確保されるべきで点に留意しましょう。</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHAcEsusJ8v"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "\n",
        "# holdout\n",
        "X_train,X_test,y_train,y_test= train_test_split(X_ohe,\n",
        "                                                y,\n",
        "                                                test_size=0.20,\n",
        "                                                random_state=0)\n",
        "# resampling\n",
        "X_train_under, y_train_under = rus.fit_sample(X_train, y_train)\n",
        "X_train_over, y_train_over = ros.fit_sample(X_train, y_train)\n",
        "X_train_smt, y_train_smt = smt.fit_sample(X_train, y_train)\n",
        "\n",
        "# modeling\n",
        "pipe_gb = Pipeline([('scl',StandardScaler()),\n",
        "                    ('est',GradientBoostingClassifier(random_state=1))])\n",
        "# evaluation\n",
        "###############################################\n",
        "pipe_gb.fit(X_train,\n",
        "            y_train)\n",
        "print('Original Train:', \n",
        "      f1_score(y_train,\n",
        "               pipe_gb.predict(X_train)))\n",
        "print('Original Test:', \n",
        "      f1_score(y_test,\n",
        "               pipe_gb.predict(X_test)))\n",
        "###############################################\n",
        "pipe_gb.fit(X_train_under,\n",
        "            y_train_under)\n",
        "print('Undersampling Train:',\n",
        "      f1_score(y_train_under,\n",
        "               pipe_gb.predict(X_train_under)))\n",
        "print('Undersampling Test:', \n",
        "      f1_score(y_test,\n",
        "               pipe_gb.predict(X_test)))\n",
        "###############################################\n",
        "pipe_gb.fit(X_train_over,\n",
        "            y_train_over)\n",
        "print('Oversampling Train:',\n",
        "      f1_score(y_train_over,\n",
        "               pipe_gb.predict(X_train_over)))\n",
        "print('Oversampling Test:',\n",
        "      f1_score(y_test,\n",
        "               pipe_gb.predict(X_test)))\n",
        "###############################################\n",
        "pipe_gb.fit(X_train_smt,\n",
        "            y_train_smt)\n",
        "print('SMOTE Train:',\n",
        "      f1_score(y_train_smt,\n",
        "               pipe_gb.predict(X_train_smt)))\n",
        "print('SMOTE Test:',\n",
        "      f1_score(y_test,\n",
        "               pipe_gb.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78n6ZffIsJ8w"
      },
      "source": [
        "上記結果から、本データについては不均衡を「完全に解消する」メリットは見られませんでした。不均衡を解消する前のモデルパフォーマンスを定量的に把握した上で、不均衡をどの程度解消するとパフォーマンスがどのように変化するかを記録し、エビデンスを持った対応を心掛けましょう。"
      ]
    }
  ]
}