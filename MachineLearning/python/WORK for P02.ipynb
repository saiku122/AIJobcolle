{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "WORK for P02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saiku122/AIJobcolle/blob/master/MachineLearning/python/WORK%20for%20P02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47jWosM2laeQ"
      },
      "source": [
        "# WORK for P02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKpUFtQplaef"
      },
      "source": [
        "## [Work-1]  \n",
        "以下の設問に答えて下さい。\n",
        "###### Q1.リッジ回帰とはどのようなアルゴリズムか（OLSとの違いは）？  \n",
        "①OLSにL2正則化項を加え過学習の影響を防ぐためのアルゴリズム\n",
        "\n",
        "\n",
        "###### Q2. 過学習への対処法を４つ挙げよ。\n",
        "\n",
        "\n",
        "###### Q3. ランダムフォレストのmax_depthのデフォルトはNoneとなっている。どのような決定木が生成されるか説明せよ。\n",
        "Reference: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        ">max_depth : integer or None, optional (default=None)  \n",
        ">The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "\n",
        "##### Q4. sklearnのGradientBoostingRregressorのmax_depthのデフォルトを確認せよ。\n",
        "Reference: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lOOKT6ilaei"
      },
      "source": [
        "## [Work-2-1]  \n",
        "以下コードを一度よく確認してから実行し、正常終了することを確認して下さい。アンサンブル学習の強さ（R2値が相対的に高い）が確認できるはずです。もちろん、このデータだけで結論を一般化はできませんが、アンサンブル学習はその汎化能力の高さから広く活用されていることを覚えておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ColvKj-Wlaej"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# set dataframe\n",
        "dataset = load_boston()\n",
        "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "y = pd.Series(dataset.target, name='y')\n",
        "\n",
        "# holdout\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=0)\n",
        "# make pipelines for modeling\n",
        "pipe_ols = Pipeline([('scl',StandardScaler()),('est',LinearRegression())])\n",
        "pipe_ridge = Pipeline([('scl',StandardScaler()),('est',Ridge(random_state=1))])\n",
        "pipe_rf = Pipeline([('scl',StandardScaler()), ('est',RandomForestRegressor(random_state=1))])\n",
        "pipe_gbr = Pipeline([('scl',StandardScaler()),('est',GradientBoostingRegressor(random_state=1))])\n",
        "\n",
        "# build models\n",
        "pipe_ols.fit(X_train, y_train)\n",
        "pipe_ridge.fit(X_train, y_train)\n",
        "pipe_rf.fit(X_train, y_train)\n",
        "pipe_gbr.fit(X_train, y_train)\n",
        "\n",
        "# print the performance\n",
        "print('R2 score of OLS: %.6f' % r2_score(y_test, pipe_ols.predict(X_test)))\n",
        "print('R2 score of Ridge: %.6f' % r2_score(y_test, pipe_ridge.predict(X_test)))\n",
        "print('R2 score of RandomForest: %.6f' % r2_score(y_test, pipe_rf.predict(X_test)))\n",
        "print('R2 score of GradinetBoostingRegressor: %.6f' % r2_score(y_test, pipe_gbr.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ex-ZwBqlael"
      },
      "source": [
        "## [Work-2-2]  \n",
        "以下コードを完成させ（Work2-1の再現）、正常終了させよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ua8_olOGlaem"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.[----------] import StandardScaler\n",
        "from sklearn.[----------] import LinearRegression, Ridge\n",
        "from sklearn.[----------] import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.[----------] import train_test_split\n",
        "from sklearn.[----------] import Pipeline\n",
        "from sklearn.[----------] import r2_score\n",
        "\n",
        "# set dataframe\n",
        "dataset = load_boston()\n",
        "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "y = pd.Series(dataset.target, name='y')\n",
        "\n",
        "# holdout\n",
        "X_train, [----------], y_train, [----------] = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "# make pipelines for modeling\n",
        "pipe_ols = Pipeline([('scl',StandardScaler()),('est',[----------])])\n",
        "pipe_ridge = Pipeline([('scl',StandardScaler()),('est',[----------](random_state=1))])\n",
        "pipe_rf = Pipeline([('scl',StandardScaler()),('est',[----------](random_state=1))])\n",
        "pipe_gbr = Pipeline([('scl',StandardScaler()),('est',[----------](random_state=1))])\n",
        "\n",
        "# build models\n",
        "pipe_ols.[----------](X_train, y_train)\n",
        "pipe_ridge.[----------](X_train, y_train)\n",
        "pipe_rf.[----------](X_train, y_train)\n",
        "pipe_gbr.[----------](X_train, y_train)\n",
        "\n",
        "# print the performance\n",
        "print('R2 score of OLS: %.6f' % r2_score(y_test, pipe_ols.[----------](X_test)))\n",
        "print('R2 score of Ridge: %.6f' % r2_score(y_test, pipe_ridge.[----------](X_test)))\n",
        "print('R2 score of RandomForest: %.6f' % r2_score(y_test, pipe_rf.[----------](X_test)))\n",
        "print('R2 score of GradinetBoostingRegressor: %.6f' % r2_score(y_test, pipe_gbr.[----------](X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_xXzVMOlaen"
      },
      "source": [
        "## [Work-2-3]  \n",
        "以下のコードを完成させ（Work-2-1の再現）、正常終了させよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "P3wtbD3Flaeo"
      },
      "source": [
        "# import libraries\n",
        "import [----------] as pd\n",
        "import [----------] as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.[----------] import Standard[----------]\n",
        "from sklearn.[----------] import Linear[----------], [----------]\n",
        "from sklearn.[----------] import Random[----------], Gradient[----------]\n",
        "from sklearn.[----------] import train_[----------]\n",
        "from sklearn.[----------] import Pipe[----------]\n",
        "from sklearn.[----------] import r2_[----------]\n",
        "\n",
        "# set dataframe\n",
        "dataset = load_boston()\n",
        "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "y = pd.Series(dataset.target, name='y')\n",
        "\n",
        "# holdout\n",
        "[----------], [----------], y_train, [----------] = [----------](X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "# make pipelines for modeling\n",
        "pipe_ols = Pipeline([('scl',[----------]),('est',[----------])])\n",
        "pipe_ridge = Pipeline([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "pipe_rf = Pipeline([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "pipe_gbr = Pipeline([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "\n",
        "# build models\n",
        "pipe_ols.[----------]([----------], [----------])\n",
        "pipe_ridge.[----------]([----------], [----------])\n",
        "pipe_rf.[----------]([----------], [----------])\n",
        "pipe_gbr.[----------]([----------], [----------])\n",
        "\n",
        "# print the performance\n",
        "print('R2 score of OLS: %.6f' % r2_score(y_test, pipe_ols.[----------](X_test)))\n",
        "print('R2 score of Ridge: %.6f' % r2_score(y_test, pipe_ridge.[----------](X_test)))\n",
        "print('R2 score of RandomForest: %.6f' % r2_score(y_test, pipe_rf.[----------](X_test)))\n",
        "print('R2 score of GradinetBoostingRegressor: %.6f' % r2_score(y_test, pipe_gbr.[----------](X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUDjJaPdlaeq"
      },
      "source": [
        "## [Work-2-4]  \n",
        "以下のコードを完成させ（Work-2-1の再現）、正常終了させよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1pTJbA80laet"
      },
      "source": [
        "# import libraries\n",
        "import [----------] as pd\n",
        "import [----------] as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.[----------] import [----------]  #前処理\n",
        "from sklearn.[----------] import [----------],[----------]  #線形モデル\n",
        "from sklearn.[----------] import [----------],[----------]  #アンサンブルモデル\n",
        "from sklearn.[----------] import [----------]  #holdout\n",
        "from sklearn.[----------] import [----------]  #パイプライン\n",
        "from sklearn.[----------] import [----------]  #R2スコア\n",
        "\n",
        "# set dataframe\n",
        "dataset = load_boston()\n",
        "X = pd.[----------](dataset.data, columns=dataset.feature_names)\n",
        "y = pd.[----------](dataset.target, name='y')\n",
        "\n",
        "# holdout\n",
        "[----------], [----------], [----------], [----------] = [----------](X,y,[----------]=0.20,random_state=0)\n",
        "\n",
        "# make pipelines for modeling\n",
        "pipe_ols = [----------]([('scl',[----------]),('est',[----------])])\n",
        "pipe_ridge = [----------]([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "pipe_rf = [----------]([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "pipe_gbr = [----------]([('scl',[----------]),('est',[----------](random_state=1))])\n",
        "\n",
        "# build models\n",
        "pipe_ols.[----------]([----------], [----------])\n",
        "pipe_ridge.[----------]([----------], [----------])\n",
        "pipe_rf.[----------]([----------], [----------])\n",
        "pipe_gbr.[----------]([----------], [----------])\n",
        "\n",
        "# print the performance\n",
        "print('R2 score of OLS: %.6f' % r2_score(y_test, pipe_ols.[----------](X_test)))\n",
        "print('R2 score of Ridge: %.6f' % r2_score(y_test, pipe_ridge.[----------](X_test)))\n",
        "print('R2 score of RandomForest: %.6f' % r2_score(y_test, pipe_rf.[----------](X_test)))\n",
        "print('R2 score of GradinetBoostingRegressor: %.6f' % r2_score(y_test, pipe_gbr.[----------](X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-DABOt8laev"
      },
      "source": [
        "## [Work-3-1]（Codeの分解）    \n",
        "以下コードを実施し、正常終了することを確認せよ。データの読み込み、データ前処理、アルゴリズムの呼び出し、交叉検証準備、一連の処理を束ねる便利機能、評価指標の呼び出しと、モデル構築に必要な機能が網羅されていることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "R6LMJtsZlaew"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAewTfnslaex"
      },
      "source": [
        "## [Work-3-2]（Codeの分解）    \n",
        "サンプルデータ（dataset）の属性dataはNumpyのarray（配列型）であることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mZ6vmz86laey"
      },
      "source": [
        "# set dataframe\n",
        "dataset = load_boston()\n",
        "dataset.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEbqhczRlaey"
      },
      "source": [
        "## [Work-3-3]（Codeの分解）    \n",
        "サンプルデータ（dataset）の属性feature_namesはNumpyのarray（配列型）であることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ocoxOKu0laez"
      },
      "source": [
        "dataset.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofC6YdyTlaez"
      },
      "source": [
        "## [Work-3-4]（Codeの分解）    \n",
        "特徴量ベクトル（dataset.data）とカラム名（dataset.feature_names）からデータフレームが構成されることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WuqZVPV8lae0"
      },
      "source": [
        "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "X.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsE8L2uDlae0"
      },
      "source": [
        "## [Work-3-5]（Codeの分解）  \n",
        "正解データがdatasetオブジェクトの属性targetでNumpyのarray型で格納されていることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RllO4GK1lae0"
      },
      "source": [
        "dataset.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0MvEGQnlae1"
      },
      "source": [
        "## [Work-3-6]（Codeの分解）  \n",
        "正解データをカラム名\"y\"でシリーズ化していることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "C2y-dvmAlae1"
      },
      "source": [
        "y = pd.Series(dataset.target, name='y')\n",
        "y.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV2AO9fHlae1"
      },
      "source": [
        "## [Work-3-7]（Codeの分解）  \n",
        "train_test_split関数によって、Xとyが80%:20%に分割されていることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GRYqBUtKlae2"
      },
      "source": [
        "# cross-validation(holdout)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n",
        "\n",
        "# print the shape\n",
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEhIpMZ2lae2"
      },
      "source": [
        "## [Work-3-8]（Codeの分解）  \n",
        "パイプラインの構成要素をnamed_stepsで呼び出さることを確認せよ。  \n",
        "StandardScalerは学習データの各変数（縦方向）の平均と標準偏差を記憶し標準化するためのライブラリである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lXoI_QNJlae2"
      },
      "source": [
        "# make pipelines for modeling\n",
        "pipe_ridge = Pipeline([('scl',StandardScaler()),('est',Ridge())])\n",
        "pipe_gbr = Pipeline([('scl',StandardScaler()),('est',GradientBoostingRegressor(random_state=1))])\n",
        "\n",
        "# get pipeline elements\n",
        "pipe_ridge.named_steps['scl']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqNkcbKalae3"
      },
      "source": [
        "## [Work-3-9]（Codeの分解）  \n",
        "パイプラインの構成要素をnamed_stepsで呼び出さることを確認せよ。  \n",
        "呼び出されたリッジ回帰のパラメータalphaが正則化項の重みであることを思い出すこと。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Jgv_G7ytlae3"
      },
      "source": [
        "# get pipeline elements\n",
        "pipe_ridge.named_steps['est']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd7IWHFflae3"
      },
      "source": [
        "## [Work-3-10]（Codeの分解）  \n",
        "以下のコードを実行し、パイプラインの構成要素をnamed_stepsで呼び出さることを確認せよ。呼び出された勾配ブースティングのパラメータn_estimators=100は決定木を100本直列で学習させるということである。パラメータmax_depth=3は各決定木の深さである。またrandome_stateが指定した値であることも確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hlm5m_gYlae3"
      },
      "source": [
        "# get pipeline elements\n",
        "pipe_gbr.named_steps['est']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN5WOK9Wlae4"
      },
      "source": [
        "また以下パラメータについて、以下のイメージが持てるか確認しましょう。\n",
        "- n_estimatorsを大きくすると過学習の危険性が増える\n",
        "- max_depthを大きくすると過学習の危険性が増える\n",
        "- random_stateを指定しないと同じモデルを再現できなくなる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kjd1cY_lae4"
      },
      "source": [
        "## [Work-3-11]（Codeの分解）  \n",
        "r2_score(正解ベクトル, 予測ベクトル)でR2値が取得できることを確認せよ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kUJ-zpiSlae4"
      },
      "source": [
        "print(r2_score(y_test, pipe_ridge.predict(X_test)))\n",
        "print(r2_score(y_test, pipe_gbr.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}