{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: one-hotエンコーディング・欠損値処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encodingと欠損値処理を学ぶため、ローン審査結果データを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sample data: Loan screening data for classification \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv',header=0)\n",
    "X = df.iloc[:,:-1]           # 最終列以前を特徴量X\n",
    "X = X.drop('Loan_ID',axis=1) # 1列目はID情報のため特徴量から削除\n",
    "y = df.iloc[:,-1]            # 最終列を正解データ\n",
    "\n",
    "# check the shape\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "\n",
    "# ローン審査でNOとなったサンプルを1（正例）へ変換\n",
    "class_mapping = {'N':1, 'Y':0}\n",
    "y = y.map(class_mapping)\n",
    "print('--------------------')\n",
    "print(y.value_counts())\n",
    "X.join(y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データフレームの表示列数を50に拡張するよう、オプション変更をしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて上記データを使って、以下のような前処理方法を学びます。\n",
    "- <b>欠損値補完</b>：LoanAmountの1行目の欠損値をLoanAmount列の平均値で置き換える\n",
    "- <b>one-hotエンコーディング</b>：Genderなどのカテゴリ変数を0/1のバイナリ変数に変換する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本講座では一連の前処理を、以下のような順番で統一します。\n",
    "1. まず、<b>カテゴリ変数の欠損値</b>をone-hotエンコードをして解決し、\n",
    "1. 次に、<b>数値変数の欠損値</b>を平均値で置き換え解決する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではone-hotエンコードの実施です。dummy_na=Trueとすると、欠損であったという情報も含めone-hot化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_columns = ['Dependents',\n",
    "               'Gender',\n",
    "               'Married',\n",
    "               'Education',\n",
    "               'Self_Employed',\n",
    "               'Property_Area']\n",
    "\n",
    "X_new = pd.get_dummies(X,\n",
    "                       dummy_na=True,\n",
    "                       columns=ohe_columns)\n",
    "\n",
    "display(X_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記まででカテゴリ変数の数量化と欠損値対応は終了です。<br>次に数値変数の欠損を平均値で置き換えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値変数の欠損値置換処理の正常確認のため、LoanAmount列の基礎統計量を確認しておきます。平均値が146.412162であることを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、連続変数の欠損値の平均値補完の実行です。`sklearn.impute`モジュールの`SimpleImputer`クラスを読み込みます。SimpleImputerクラスのメソッドtransfomrを適用することで、LoanAmountの欠損値（1行目など）を平均値（146.412162）に置換できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# インピュータークラスのインスタンス化と（列平均の）学習\n",
    "imp = SimpleImputer()\n",
    "imp.fit(X_new)\n",
    "\n",
    "# 学習済みImputerの適用：各列の欠損値の置換\n",
    "X_new_columns = X_new.columns.values\n",
    "X_new = pd.DataFrame(imp.transform(X_new),columns=X_new_columns)\n",
    "\n",
    "# 結果表示\n",
    "display(X_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で、カテゴリ変数の数量化と欠損対応、数値変数の欠損値対応は終了です。もし特徴量の次元数（列数）が小さければ、そのままアルゴリズムに投入して構いません。ただし、実務では数百・数千次元を超えることがしばしばありますので、その際は以下の次元圧縮を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: 次元圧縮（RFE&PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて、特徴量が元の11次元が26次元まで増加しました。<br><b>ここではRFEを使って、予測に役立つと判断された上位10変数に絞り込むこととします。</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 特徴量因子の重要度を推定する分類器をRandomForestClassifierに設定\n",
    "# 最終的に残す特徴量を10に設定\n",
    "# 1回のstepで削除する次元数は5%ずつとした\n",
    "selector = RFE(estimator=RandomForestClassifier(n_estimators=100,random_state=0),\n",
    "               n_features_to_select=10,\n",
    "               step=.05)\n",
    "selector.fit(X_new,y)\n",
    "print('Done normally')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFEをfitすることで、26変数のうちどの変数を残すかが決定されました。<br><b>残された変数の確認は\"support_\"属性を呼び出すことで可能です。</b><br>Trueが採用された変数の場所を表しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(selector.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitまでで残すべき変数を決めることができたので、実際にデータの絞り込みをします。<br>`SimpleImputer`クラスの`transform`メソッドで列の絞り込みができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 26次元を10次元を圧縮\n",
    "X_new_selected=selector.transform(X_new)\n",
    "X_new_selected=pd.DataFrame(X_new_selected,\n",
    "                            columns=X_new_columns[selector.support_])\n",
    "print('X shape after RFE:', X_new_selected.shape)\n",
    "print('---------------------------------------')\n",
    "print(X_new_selected.dtypes)\n",
    "X_new_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFEによる次元圧縮の実行例は以上で終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、PCAによる次元圧縮の方法を確認します。<br>X_new（RFE前の26次元）を対象にPCAで特徴抽出したい場合は、以下の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# パイプラインにPCAを埋め込めば自動的に次元圧縮してくれる\n",
    "clf = Pipeline([('scl', StandardScaler()),\n",
    "                ('reduct', PCA(n_components=10,random_state=1)),\n",
    "                ('clf', GradientBoostingClassifier(random_state=1))])\n",
    "\n",
    "# 学習時に自動的にPCA処理が施される\n",
    "clf.fit(X_new, y)\n",
    "print('Normally done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習器clfの実態はパイプラインですから、<b>これを学習済みモデルとして保存しておけば、学習済みscl、学習済みreduct(PCA)、学習済みclf（モデル）の3つが学習状態で保存（永続化）されます</b>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[確認してみよう]</b> 学習済みモデルの永続化の方法をScikit-learnの公式ドキュメントで調査しよう。\n",
    "- https://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[確認してみよう]</b> 特徴量選択のクラスにRFECVがあります。RFEと何が違うかScikit-learnの公式ドキュメントで調べてみよう。\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
