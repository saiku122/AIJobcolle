{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スコアリングフェーズにおけるデータ処理（課題把握編）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ローン審査データを使って<b>モデリング段階のデータ処理フローをおさらいし、</b><br>その後、スコアリング段階のデータ処理で必要となるテクニックを学びましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：モデル用データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sample data: Loan screening data for classification \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/av_loan_u6lujuX_CVtuZ9i.csv',header=0)\n",
    "X  = df.iloc[:,:-1]           # 最終列以前を特徴量X\n",
    "ID = X.iloc[:,[0]]            # 最初列がPK（Loan_ID）なのでID情報としてセット\n",
    "X  = X.drop('Loan_ID',axis=1) # 1列目(Loan_ID)は特徴量ベクトルから削除\n",
    "y  = df.iloc[:,-1]            # 最終列を正解データ\n",
    "\n",
    "# check the shape\n",
    "print('--------------------------------------')\n",
    "print('Raw shape: (%i,%i)' %df.shape)\n",
    "print('X shape: (%i,%i)' %X.shape)\n",
    "\n",
    "# ローン審査でNOとなったサンプルを1（正例）として変換\n",
    "class_mapping = {'N':1, 'Y':0}\n",
    "y = y.map(class_mapping)\n",
    "print('---------------------------------------')\n",
    "print(y.value_counts())\n",
    "print('---------------------------------------')\n",
    "print(ID.join(X).join(y).dtypes)\n",
    "ID.join(X).join(y).head()\n",
    "\n",
    "# 表示列数のオプション変更\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：カテゴリ変数の数量化と欠損対応\n",
    "まず、カテゴリ変数のone-hotエンコーディングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = ['Dependents',\n",
    "               'Gender',\n",
    "               'Married',\n",
    "               'Education',\n",
    "               'Self_Employed',\n",
    "               'Property_Area']\n",
    "\n",
    "X_ohe = pd.get_dummies(X,\n",
    "                       dummy_na=True,\n",
    "                       columns=ohe_columns)\n",
    "\n",
    "print('X_ohe shape:(%i,%i)' % X_ohe.shape)\n",
    "display(X_ohe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：数値変数の欠損対応\n",
    "次に、数値変数の欠損値を各列平均値で置換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 欠損値NaNを平均値(mean)で置換\n",
    "imp = SimpleImputer()\n",
    "imp.fit(X_ohe)\n",
    "\n",
    "# 学習済みImputerを適用しX_newの欠損値を置換\n",
    "X_ohe_columns = X_ohe.columns.values\n",
    "X_ohe = pd.DataFrame(imp.transform(X_ohe), columns=X_ohe_columns)\n",
    "\n",
    "# 結果表示\n",
    "display(X_ohe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### モデル用データの前処理：次元圧縮（特徴選択）\n",
    "続けて、特徴次元の圧縮を図ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "selector = RFE(RandomForestClassifier(n_estimators=100,random_state=1),\n",
    "               n_features_to_select=10,\n",
    "               step=.05)\n",
    "\n",
    "selector.fit(X_ohe,y)\n",
    "\n",
    "X_fin = pd.DataFrame(selector.transform(X_ohe),\n",
    "                     columns=X_ohe_columns[selector.support_])\n",
    "\n",
    "print('X_fin shape:(%i,%i)' % X_fin.shape)\n",
    "X_fin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでがモデリング段階でのデータ加工でした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理\n",
    "さて、スコア用データの前処理です。本処理は以下要件を満たす必要があります。\n",
    "- 上記10次元の特徴量をこの並びの通りに変換する必要\n",
    "- 学習済みSimpleImputerインスタンスによる欠損値補完\n",
    "- 学習済みRFEインスタンスによる特徴量選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なぜなら、以下理由のためです。\n",
    "- モデル用データとスコア用データの並び順が違うことを学習済みモデルはわからない\n",
    "- 並び順が異なると、学習済みSimpleImputerも学習済みRFEもインデックス情報が狂う\n",
    "- 数値変数の欠損値は「学習段階」の平均値でしか置換できない（未来情報は使えない）\n",
    "- 何が重要な変数かは「学習段階」のXとyの関係からしか知りようがない（同上）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データへの前処理：データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sample data for classificatio\n",
    "df_s = pd.read_csv('./data/av_loan_test_Y3wMUE5_7gLdaTN.csv', header=0)\n",
    "ID_s = df_s.iloc[:,[0]]            # 第0列はPK（Loan_ID）なのでIDとしてセット\n",
    "X_s  = df_s.drop('Loan_ID',axis=1) # Loan_IDはID情報なので特徴ベクトルから削除\n",
    "\n",
    "# check the shape\n",
    "print('Raw shape: (%i,%i)' %df_s.shape)\n",
    "print('X shape: (%i,%i)' %X_s.shape)\n",
    "print('-------------------------------')\n",
    "print(X_s.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：カテゴリ変数の数量化と欠損対応\n",
    "本処理はスコア用データに対し、モデル用データとは独立に実施します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_s = pd.get_dummies(X_s,\n",
    "                         dummy_na=True,\n",
    "                         columns=ohe_columns)\n",
    "print('X_ohe_s shape:(%i,%i)' % X_ohe_s.shape)\n",
    "X_ohe_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### スコア用データの前処理：one-hotエンコーディング後のデータ整合チェック\n",
    "さて、one-hotエンコーディング後のモデル用とスコア用データの整合性を確認してみます。\n",
    "確認のため、Pythonのset型（集合型変数）を利用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonの集合型変数を利用\n",
    "cols_model = set(X_ohe.columns.values)\n",
    "cols_score = set(X_ohe_s.columns.values)\n",
    "\n",
    "# モデルにはあったスコアにはないデータ項目\n",
    "diff1 = cols_model - cols_score\n",
    "print('Modelのみ:%s' % diff1)\n",
    "\n",
    "# スコアにはあるがモデルになかったデータ項目\n",
    "diff2 = cols_score - cols_model\n",
    "print('Scoreのみ:%s' % diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実は、このスコア用データは、以下２つの細工が施されていました。\n",
    "1. Gender変数に\"Unknown\"というカテゴリ値を新しく追加\n",
    "2. Dependents変数の\"3+\"というカテゴリ値を除外（残された値は0,1,2の3種類）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果としてモデル用とスコア用のデータ間で、以下不整合の生じる可能性があるとわかります。\n",
    "1. モデルデータにないカラムが生成される可能性（Gender_Unknown)\n",
    "1. モデルデータにあったカラムが消える可能性（Dependents_3+）\n",
    "1. データ型の違いが理由で①/②が生じる可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のJupyterファイル「スコアリングフェーズにおけるデータ処理（解決編）」で上記の不整合への対処を学びましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
